{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pandas import DataFrame, Series\n",
    "import random\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns that needs to be scraped from the website\n",
    "\n",
    "columns = ['Year','Name','Positions','Age','Rating','Potential','Team','Contract','ID','Height','Weight','Foot','Best Overall','Best Position'\n",
    "           ,'Growth','Joined','Loan End Date','Value','Wage','Release Clause','Total Attacking','Crossing','Finishing',\n",
    "           'Heading Accuracy','Short Passing','Volleys','Total Skill','Dribbling','Curve','FK Accuracy','Long Passing',\n",
    "          'Ball Control','Total Movement','Acceleration','Sprint Speed','Agility','Reactions','Balance','Total Power',\n",
    "          'Short Power','Jumping','Stamina','Strength','Long Shots','Total Mentality','Aggression','Interceptions',\n",
    "           'Positioning','Vision','Penalties','Composure','Total Defending','Marking','Standing Tackle','Sliding Tackle',\n",
    "          'Total GK','GK Diving','GK Handling','GK Kicking','GK Positioning','GK Reflexes','Total Stats','Base Stats',\n",
    "           'Weak Foot','Skill Moves','Attacking Work Rate','Defensive Work Rate','International Reputation','PAC','SHO',\n",
    "           'PAS','DRI','DEF','PHY','HITS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_players_details(year):\n",
    "    \"\"\"\n",
    "    Scrapes data from SoFiFa.com website for each year from 2008 to 2020 and creates a new csv file for each year\n",
    "    \n",
    "    Parameters:\n",
    "    year  : the year for which data needs to be scraped\n",
    "    \n",
    "    \"\"\"\n",
    "     \n",
    "    year_split = year[2:]\n",
    "    base_url = f\"https://sofifa.com/players?col=oa&sort=desc&showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=hi&showCol%5B3%5D=wi&showCol%5B4%5D=pf&showCol%5B5%5D=oa&showCol%5B6%5D=pt&showCol%5B7%5D=bo&showCol%5B8%5D=bp&showCol%5B9%5D=gu&showCol%5B10%5D=jt&showCol%5B11%5D=le&showCol%5B12%5D=vl&showCol%5B13%5D=wg&showCol%5B14%5D=rc&showCol%5B15%5D=ta&showCol%5B16%5D=cr&showCol%5B17%5D=fi&showCol%5B18%5D=he&showCol%5B19%5D=sh&showCol%5B20%5D=vo&showCol%5B21%5D=ts&showCol%5B22%5D=dr&showCol%5B23%5D=cu&showCol%5B24%5D=fr&showCol%5B25%5D=lo&showCol%5B26%5D=bl&showCol%5B27%5D=to&showCol%5B28%5D=ac&showCol%5B29%5D=sp&showCol%5B30%5D=ag&showCol%5B31%5D=re&showCol%5B32%5D=ba&showCol%5B33%5D=tp&showCol%5B34%5D=so&showCol%5B35%5D=ju&showCol%5B36%5D=st&showCol%5B37%5D=sr&showCol%5B38%5D=ln&showCol%5B39%5D=te&showCol%5B40%5D=ar&showCol%5B41%5D=in&showCol%5B42%5D=po&showCol%5B43%5D=vi&showCol%5B44%5D=pe&showCol%5B45%5D=cm&showCol%5B46%5D=td&showCol%5B47%5D=ma&showCol%5B48%5D=sa&showCol%5B49%5D=sl&showCol%5B50%5D=tg&showCol%5B51%5D=gd&showCol%5B52%5D=gh&showCol%5B53%5D=gc&showCol%5B54%5D=gp&showCol%5B55%5D=gr&showCol%5B56%5D=tt&showCol%5B57%5D=bs&showCol%5B58%5D=wk&showCol%5B59%5D=sk&showCol%5B60%5D=aw&showCol%5B61%5D=dw&showCol%5B62%5D=ir&showCol%5B63%5D=pac&showCol%5B64%5D=sho&showCol%5B65%5D=pas&showCol%5B66%5D=dri&showCol%5B67%5D=def&showCol%5B68%5D=phy&r={year_split}0002&set=true&offset=\"\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    offset = 0\n",
    "    for offset in range(300):\n",
    "        url = base_url + str(offset*60)\n",
    "        source_code = requests.get(url)\n",
    "        plain_text = source_code.text\n",
    "        soup = BeautifulSoup(plain_text)\n",
    "        table_body = soup.find('tbody')\n",
    "        for row in table_body.findAll('tr'):\n",
    "            td = row.findAll('td')\n",
    "            year = year\n",
    "            name = td[1].findAll('a')[1].text.strip()\n",
    "            positions = ','.join(pos.text.strip() for pos in td[1].findAll('a',{'rel': 'nofollow'}))[1:]\n",
    "            age = td[2].text.strip()\n",
    "            rating = td[3].text.strip()\n",
    "            potential = td[4].text.strip()\n",
    "            team = td[5].find('a').text.strip()\n",
    "            contract = td[5].find('div',{'class':'sub'}).text.strip()\n",
    "            pid = td[6].text.strip()\n",
    "            height = td[7].text.strip()\n",
    "            weight = td[8].text.strip()\n",
    "            foot = td[9].text.strip()\n",
    "            bestOverall = td[10].text.strip()\n",
    "            bestPosition = td[11].text.strip()\n",
    "            growth = td[12].text.strip()\n",
    "            joined = td[13].text.strip()\n",
    "            loanEndDate = td[14].text.strip()\n",
    "            value = td[15].text.strip()\n",
    "            wage = td[16].text.strip()\n",
    "            releaseClause = td[17].text.strip()\n",
    "            totalAttacking = td[18].text.strip()\n",
    "            crossing = td[19].text.strip()\n",
    "            finishing = td[20].text.strip()\n",
    "            headingAccuray = td[21].text.strip()\n",
    "            shortPassing = td[22].text.strip()\n",
    "            volleys = td[23].text.strip()\n",
    "            totalSkill = td[24].text.strip()\n",
    "            dribbling = td[25].text.strip()\n",
    "            curve = td[26].text.strip()\n",
    "            fkAccuracy = td[27].text.strip()\n",
    "            longPassing = td[28].text.strip()\n",
    "            ballControl = td[29].text.strip()\n",
    "            totalMovement = td[30].text.strip()\n",
    "            acceleration = td[31].text.strip()\n",
    "            sprintSpeed = td[32].text.strip()\n",
    "            agility = td[33].text.strip()\n",
    "            reactions = td[34].text.strip()\n",
    "            balance = td[35].text.strip()\n",
    "            totalPower = td[36].text.strip()\n",
    "            shortPower = td[37].text.strip()\n",
    "            jumping = td[38].text.strip()\n",
    "            stamina = td[39].text.strip()\n",
    "            strength = td[40].text.strip()\n",
    "            longShots = td[41].text.strip()\n",
    "            totalMentality = td[42].text.strip()\n",
    "            aggression = td[43].text.strip()\n",
    "            interceptions = td[44].text.strip()\n",
    "            positioning = td[45].text.strip()\n",
    "            vision = td[46].text.strip()\n",
    "            penalties = td[47].text.strip()\n",
    "            composure = td[48].text.strip()\n",
    "            totalDefending = td[49].text.strip()\n",
    "            marking = td[50].text.strip()\n",
    "            standingTackle = td[51].text.strip()\n",
    "            slidingTackle = td[52].text.strip()\n",
    "            totalGoalKeeping = td[53].text.strip()\n",
    "            GKDiving = td[54].text.strip()\n",
    "            GKHandling = td[55].text.strip()\n",
    "            GKKicking = td[56].text.strip()\n",
    "            GKPositioning = td[57].text.strip()\n",
    "            GKReflexes = td[58].text.strip()\n",
    "            totalStats = td[59].text.strip()\n",
    "            baseStats = td[60].text.strip()\n",
    "            weakFoot = td[61].text.strip()\n",
    "            skillMoves = td[62].text.strip()\n",
    "            attWorkRate = td[63].text.strip()\n",
    "            defWorkRate = td[64].text.strip()\n",
    "            intRep = td[65].text.strip()\n",
    "            pac = td[66].text.strip()\n",
    "            sho = td[67].text.strip()\n",
    "            pas = td[68].text.strip()\n",
    "            dri = td[69].text.strip()\n",
    "            de = td[70].text.strip()\n",
    "            phy = td[71].text.strip()\n",
    "            hits = td[72].text.strip()\n",
    "            player_data = pd.DataFrame([[year,name,positions,age,rating,potential,team,contract,pid,height,weight,foot,bestOverall,bestPosition,\n",
    "                             growth,joined,loanEndDate,value,wage,releaseClause,totalAttacking,crossing,finishing,headingAccuray,\n",
    "                             shortPassing,volleys,totalSkill,dribbling,curve,fkAccuracy,longPassing,ballControl,totalMovement,\n",
    "                              acceleration,sprintSpeed,agility,reactions,balance,totalPower,shortPower,jumping,stamina,strength,\n",
    "                             longShots,totalMentality,aggression,interceptions,positioning,vision,penalties,composure,\n",
    "                              totalDefending,marking,standingTackle,slidingTackle,totalGoalKeeping,GKDiving,GKHandling,GKKicking,\n",
    "                             GKPositioning,GKReflexes,totalStats,baseStats,weakFoot,skillMoves,attWorkRate,defWorkRate,intRep,\n",
    "                             pac,sho,pas,dri,de,phy,hits]])\n",
    "            player_data.columns = columns\n",
    "            df = df.append(player_data, ignore_index=True)\n",
    "\n",
    "        offset+=1\n",
    "        if (offset % 20 == 0):\n",
    "            print(offset)\n",
    "    df.to_csv(f'player_data_{year}.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "for yr in range(2008,2021):\n",
    "    scrape_players_details(str(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all the player csv files\n",
    "\n",
    "import glob\n",
    "\n",
    "path = r'C:\\Shubhanshu\\NEU\\SML\\Project' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.to_csv('player_data_complete.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping goal and cards data for players for predicting their value for the next season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns that needs to be scraped\n",
    "cols = ['Year','ID','Name','Season','Team','Competition','MinutesPlayed','Appearances','Lineups','SubstituteIn',\n",
    "        'SubstituteOut','SubstituteBench','Goal','YellowCard','RedCard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_season_details(year):\n",
    "    \"\"\"\n",
    "    Scrapes season data for players from SoFiFa.com website for each year from 2008 to 2020 and creates a new csv file for each year\n",
    "    \n",
    "    Parameters:\n",
    "    year  : the year for which data needs to be scraped\n",
    "    \n",
    "    \"\"\"\n",
    "     \n",
    "    year_split = year[2:]\n",
    "    base_url = f\"https://sofifa.com/?r={year_split}0075&set=true?offset=\"\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    offset = 0\n",
    "    for offset in range(300):\n",
    "        url = base_url + str(offset*60)\n",
    "        source_code = requests.get(url)\n",
    "        plain_text = source_code.text\n",
    "        soup = BeautifulSoup(plain_text)\n",
    "        table_body = soup.find('tbody')\n",
    "        for row in table_body.findAll('tr'):\n",
    "            td = row.findAll('td')\n",
    "            name = td[1].findAll('a')[0].text.strip()\n",
    "            pid = td[6].text.strip()\n",
    "            link = td[1].findAll('a')[0].get('href')\n",
    "            link = '/'.join(link.split('/')[:-2]) + \"/live\" \n",
    "            html = requests.get(\"https://sofifa.com\" + link)\n",
    "            txt = html.text\n",
    "            soup1 = BeautifulSoup(txt)\n",
    "            tab_body = soup1.find('tbody')\n",
    "        \n",
    "            if(tab_body is None):\n",
    "                player_data = pd.DataFrame([[year,pid,name,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "                                        np.NaN,np.NaN,np.NaN,np.NaN,np.NaN]])\n",
    "                player_data.columns = cols\n",
    "                df = df.append(player_data, ignore_index=True)\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            for goal in tab_body.findAll('tr'):\n",
    "                tdI = goal.findAll('td')\n",
    "                year = year\n",
    "                season = tdI[0].text.strip()\n",
    "                split = season.split('/')[0]\n",
    "                if(split == year):\n",
    "                    team = tdI[1].find('a').text.strip()\n",
    "                    comp = tdI[2].find('a').text.strip()\n",
    "                    minutesPlayed = tdI[3].text.strip()\n",
    "                    appearances = tdI[4].text.strip()\n",
    "                    lineups = tdI[5].text.strip()\n",
    "                    subsituteIn = tdI[6].text.strip()\n",
    "                    subsituteOut = tdI[7].text.strip()\n",
    "                    subsituteBench = tdI[8].text.strip()\n",
    "                    goal = tdI[9].text.strip()\n",
    "                    yellowCard = tdI[10].text.strip()\n",
    "                    redCard = tdI[12].text.strip()\n",
    "                    player_data = pd.DataFrame([[year,pid,name,season,team,comp,minutesPlayed,appearances,lineups,subsituteIn,\n",
    "                                        subsituteOut,subsituteBench,goal,yellowCard,redCard]])\n",
    "                    player_data.columns = cols\n",
    "                    df = df.append(player_data, ignore_index=True)\n",
    "    \n",
    "        offset+=1\n",
    "        if (offset % 20 == 0):\n",
    "            print(offset)    \n",
    "    df.to_csv(f'player_goaldata_{year}.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in range(2008,2021):\n",
    "    scrape_player_season_details(str(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all the player csv files\n",
    "\n",
    "import glob\n",
    "\n",
    "path = r'C:\\Shubhanshu\\NEU\\SML\\Project\\Goal' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.to_csv('player_goaldata_complete.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
